# ğŸ§  RAG + LLM con LangChain, Hugging Face y Azure AI Search

Este proyecto implementa un sistema de RecuperaciÃ³n y GeneraciÃ³n Aumentada (RAG) que:

- Usa Azure Cognitive Search como base vectorial.  
- Aplica embeddings locales con `sentence-transformers` y `torch` (CPU/GPU).  
- Utiliza Azure OpenAI (GPT-3.5-Turbo) para generaciÃ³n de respuestas mediante LangGraph.  
- Integra un orquestador de agentes con LangGraph para gestionar flujo de recuperaciÃ³n y generaciÃ³n.  
- Dispone de interfaz web con Streamlit para interacciÃ³n amigable.  
- Soporta gestiÃ³n de tokens y lÃ­mites para optimizar costos.  
- Utiliza `.env` para gestiÃ³n segura de credenciales.  
- Soporta aceleraciÃ³n con `accelerate` para aprovechar GPU en embeddings.

---

## ğŸš€ Requisitos

- Python **3.12**  
- GPU compatible con **CUDA 12.1** (recomendado para embeddings y aceleraciÃ³n)  
- Dependencias gestionadas con `pyproject.toml`  
- Archivo `.env` configurado con credenciales de Azure

---

## âš¡ InstalaciÃ³n

### 1. Crea y activa un entorno virtual

En Linux/macOS:

```bash
python3 -m venv .venv
source .venv/bin/activate
```

En Windows:

```bash
python -m venv .venv
.venv\Scripts\activate
```

---

### 2. Instala PyTorch con soporte GPU (CUDA 12.1)

> ğŸ› ï¸ Este paso es **obligatorio** antes de instalar el resto.

```bash
pip install torch --index-url https://download.pytorch.org/whl/cu121
```

### 3. Instala el resto de dependencias del proyecto

```bash
pip install .
```

Si quieres tambiÃ©n herramientas de desarrollo y webapp:

```bash
pip install ".[dev]"
```
### 4. Crea y configura tu archivo .env

```ini
AZURE_SEARCH_ENDPOINT=https://<tu-endpoint>.search.windows.net
AZURE_SEARCH_KEY=<tu-clave-secreta>
AZURE_OPENAI_API_KEY=<tu-api-key>
AZURE_OPENAI_ENDPOINT=https://<openai-endpoint>.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT=koalaroute-gpt35
```

---

## ğŸ§ª Uso

### Ejecutar interfaz por consola

```bash
python main.py
```

Puedes hacer preguntas consecutivas al modelo.  
Escribe `salir` para cerrar la sesiÃ³n.

---

### Ejecutar interfaz web con Streamlit

```bash
streamlit run webapp/app.py
```

Permite planificar viajes con filtros, duraciÃ³n, presupuesto e intereses.

---

### Subir documentos al Ã­ndice Azure Cognitive Search

```bash
python uploader.py --file info.txt --title "LangChain Overview"
```

El archivo debe estar en la carpeta `data/`.

---

### Eliminar documentos por ID
```bash
    python deleter.py --id <id_documento>
```
---

## ğŸ“‚ Estructura del proyecto

```arduino
koalaRoute/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ info.txt
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ graph/
â”‚   â”œâ”€â”€ schema/
â”‚   â”œâ”€â”€ llm.py
â”‚   â”œâ”€â”€ prompt_utils.py
â”‚   â””â”€â”€ vector.py
â”œâ”€â”€ webapp/
â”‚   â”œâ”€â”€ app.py
|   â””â”€â”€ langgraph_runner.py 
â”œâ”€â”€ main.py
â”œâ”€â”€ uploader.py
â”œâ”€â”€ deleter.py
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

---

## âœ… Estado

- OrquestaciÃ³n con LangGraph funcionando con Azure OpenAI y Azure Cognitive Search.
- Embeddings con sentence-transformers acelerados con torch y accelerate.
- Interfaz web Streamlit con filtros avanzados y control de tokens.
- Manejo de tokens con tiktoken para evitar sobrecostos.
- ConfiguraciÃ³n segura con .env.
- DocumentaciÃ³n y scripts para subir/eliminar documentos en Ã­ndice.

---

## ğŸ“Œ Notas

- El sistema estÃ¡ preparado para cambiar fÃ¡cilmente entre LLM local y Azure OpenAI.
- Soporta extensiones para guardar itinerarios, historial, y futuras integraciones con FastAPI o Gradio.
- Se recomienda usar entorno virtual y evitar instalar dependencias globalmente.
- Ajusta lÃ­mites de tokens y prompts para optimizar costos en Azure OpenAI.